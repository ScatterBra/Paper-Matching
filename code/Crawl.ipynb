{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X26DyTeQR3tu",
        "outputId": "2e844fc0-1f62-4a70-aecf-b7ee38f91192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openreview-py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "D6m11g0cSDcG",
        "outputId": "1ee127dc-23cc-4b5a-b9b3-4ed671bf6d24"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openreview-py\n",
            "  Downloading openreview_py-1.52.8-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting pycryptodome (from openreview-py)\n",
            "  Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.12/dist-packages (from openreview-py) (2.32.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from openreview-py) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openreview-py) (4.67.1)\n",
            "Collecting Deprecated (from openreview-py)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting pylatexenc (from openreview-py)\n",
            "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tld>=0.12 (from openreview-py)\n",
            "  Downloading tld-0.13.1-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pyjwt in /usr/local/lib/python3.12/dist-packages (from openreview-py) (2.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openreview-py) (2.0.2)\n",
            "Collecting litellm==1.76.1 (from openreview-py)\n",
            "  Downloading litellm-1.76.1-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp>=3.10 in /usr/local/lib/python3.12/dist-packages (from litellm==1.76.1->openreview-py) (3.13.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from litellm==1.76.1->openreview-py) (8.3.0)\n",
            "Collecting fastuuid>=0.12.0 (from litellm==1.76.1->openreview-py)\n",
            "  Downloading fastuuid-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from litellm==1.76.1->openreview-py) (0.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.12/dist-packages (from litellm==1.76.1->openreview-py) (8.7.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from litellm==1.76.1->openreview-py) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from litellm==1.76.1->openreview-py) (4.25.1)\n",
            "Requirement already satisfied: openai>=1.99.5 in /usr/local/lib/python3.12/dist-packages (from litellm==1.76.1->openreview-py) (1.109.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from litellm==1.76.1->openreview-py) (2.11.10)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from litellm==1.76.1->openreview-py) (1.1.1)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from litellm==1.76.1->openreview-py) (0.12.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (from litellm==1.76.1->openreview-py) (0.22.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.18.4->openreview-py) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.18.4->openreview-py) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.18.4->openreview-py) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.18.4->openreview-py) (2025.10.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.12/dist-packages (from Deprecated->openreview-py) (1.17.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm==1.76.1->openreview-py) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm==1.76.1->openreview-py) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm==1.76.1->openreview-py) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm==1.76.1->openreview-py) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm==1.76.1->openreview-py) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm==1.76.1->openreview-py) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm==1.76.1->openreview-py) (1.22.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm==1.76.1->openreview-py) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm==1.76.1->openreview-py) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm==1.76.1->openreview-py) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=6.8.0->litellm==1.76.1->openreview-py) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.76.1->openreview-py) (3.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.76.1->openreview-py) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.76.1->openreview-py) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.76.1->openreview-py) (0.27.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.5->litellm==1.76.1->openreview-py) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.5->litellm==1.76.1->openreview-py) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.5->litellm==1.76.1->openreview-py) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.5->litellm==1.76.1->openreview-py) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.5.0->litellm==1.76.1->openreview-py) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.5.0->litellm==1.76.1->openreview-py) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.5.0->litellm==1.76.1->openreview-py) (0.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.7.0->litellm==1.76.1->openreview-py) (2024.11.6)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers->litellm==1.76.1->openreview-py) (0.35.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.76.1->openreview-py) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.76.1->openreview-py) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.76.1->openreview-py) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.76.1->openreview-py) (6.0.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.76.1->openreview-py) (1.1.10)\n",
            "Downloading openreview_py-1.52.8-py3-none-any.whl (871 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m872.0/872.0 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading litellm-1.76.1-py3-none-any.whl (9.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tld-0.13.1-py2.py3-none-any.whl (274 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastuuid-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.1/278.1 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pylatexenc\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136817 sha256=3b0b1cce4d908da0cd013b1788fc7ac137cf6a32c7bee4b367c0499b97f65934\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/3e/78/fa1588c1ae991bbfd814af2bcac6cef7a178beee1939180d46\n",
            "Successfully built pylatexenc\n",
            "Installing collected packages: pylatexenc, tld, pycryptodome, fastuuid, Deprecated, litellm, openreview-py\n",
            "Successfully installed Deprecated-1.2.18 fastuuid-0.14.0 litellm-1.76.1 openreview-py-1.52.8 pycryptodome-3.23.0 pylatexenc-2.10 tld-0.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openreview\n",
        "\n",
        "client = openreview.api.OpenReviewClient(  # 新版命名空间\n",
        "    baseurl=\"https://api2.openreview.net\",\n",
        "    username=\"yichi.zhang@stonybrook.edu\",\n",
        "    password=\"Zz76146379?\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "W5vFNl4oSVvu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openreview import tools\n",
        "\n",
        "# 例：抓取 ICLR 2026 所有投稿（提交阶段）\n",
        "ICLR26_notes = list(tools.iterget_notes(\n",
        "    client,\n",
        "    invitation=\"ICLR.cc/2026/Conference/-/Submission\"  # 有些年份是 Blind_Submission\n",
        "))\n",
        "\n",
        "print(len(ICLR26_notes))\n",
        "print(ICLR26_notes[0].content.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCUOZ5D3SuIu",
        "outputId": "d4b78441-aeea-4e84-9866-417572bfe771"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-817426461.py:4: DeprecationWarning: Call to deprecated function (or staticmethod) iterget_notes. (Use client.get_all_notes() instead) -- Deprecated since version 1.52.6.\n",
            "  ICLR26_notes = list(tools.iterget_notes(\n",
            "Getting Notes: 100%|█████████▉| 19726/19746 [00:11<00:00, 1786.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19746\n",
            "dict_keys(['title', 'keywords', 'abstract', 'primary_area', 'venue', 'venueid', 'pdf', '_bibtex'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ICLR26_notes[0].content['abstract']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQ38bgP1THPL",
        "outputId": "0994ac66-2076-4fb9-83bb-cbe3aca303c4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'value': \"Large Language Models (LLMs) demonstrate remarkable flexibility in adopting different personas and behaviors. Existing approaches typically adapt such behavior through external knowledge such as prompting, retrieval-augmented generation (RAG), or fine-tuning. We ask: do LLMs really need external context or parameters to adapting to different behaviors, or do they already have such knowledge embedded to their parameters?\\nIn this work, we show that LLMs already contain persona-specialized subnetworks in their parameter space. Using small calibration datasets, we identify distinct activation signatures associated with different personas. Guided by these statistics, we develop masking strategy that isolate lightweight persona subnetworks. Building on the findings, we further discuss: how can we discover opposing sub-network from the model that lead to binary-opposing personas, such as introvert-extrovert? \\nTo further enhance separation in binary opposition scenarios, we introduce a contrastive pruning strategy that identifies parameters responsible for the statistical divergence between opposing personas. Our method is entirely training-free, and rely solely on the language model's existing parameter space. Across diverse evaluation settings, the resulting subnetworks exhibit significantly stronger persona alignment than baselines that requires external knowledge while being more efficient. Our findings suggest that diverse human-like behaviors are not merely induced in LLMs, but are already embedded in their parameter space—pointing toward a new perspective on controllable and interpretable personalization in large language models. Our code is available at  https://anonymous.4open.science/r/C694.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# 将 note 的关键信息提取出来（比如标题、摘要、关键词）\n",
        "iclr26_data = []\n",
        "for note in ICLR26_notes:\n",
        "    content = note.content\n",
        "    iclr26_data.append({\n",
        "        \"title\": content.get(\"title\", {}).get(\"value\", \"\"),\n",
        "        \"abstract\": content.get(\"abstract\", {}).get(\"value\", \"\"),\n",
        "        \"keywords\": content.get(\"keywords\", {}).get(\"value\", \"\"),\n",
        "        \"venue\": content.get(\"venue\", \"\"),\n",
        "        \"id\": note.id\n",
        "    })\n",
        "\n",
        "# 保存为 json 文件\n",
        "with open(\"ICLR2026_submissions.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(iclr26_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"✅ 成功导出 {len(iclr26_data)} 条投稿记录到 ICLR2026_submissions.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QVSa3DcULs8",
        "outputId": "5edc919d-b24b-4d92-ad2b-e00b4efae79a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 成功导出 19746 条投稿记录到 ICLR2026_submissions.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openreview import tools\n",
        "\n",
        "# 例：抓取 ICML 2025 所有投稿（提交阶段）\n",
        "ICML25_notes = list(tools.iterget_notes(\n",
        "    client,\n",
        "    invitation=\"ICML.cc/2025/Conference/-/Submission\"  # 有些年份是 Blind_Submission\n",
        "))\n",
        "\n",
        "print(len(ICML25_notes))\n",
        "print(ICML25_notes[0].content.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEMnCD0iTSS8",
        "outputId": "fdd84193-02b6-4219-c493-fc449b1b9986"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-935663752.py:4: DeprecationWarning: Call to deprecated function (or staticmethod) iterget_notes. (Use client.get_all_notes() instead) -- Deprecated since version 1.52.6.\n",
            "  ICML25_notes = list(tools.iterget_notes(\n",
            "Getting Notes: 100%|█████████▉| 3418/3422 [00:01<00:00, 2266.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3422\n",
            "dict_keys(['title', 'authors', 'authorids', 'TLDR', 'abstract', 'primary_area', 'keywords', 'venue', 'venueid', 'pdf', '_bibtex', 'lay_summary', 'link_to_code', 'paperhash'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ICML25_notes[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMJBjWqSTlmo",
        "outputId": "e725c155-b6ec-46f8-b193-726b65419663"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Note(id = 'zydNWJzoVd',external_id = None,external_ids = None,number = 4001,cdate = 1737398300520,pdate = 1746105221791,odate = 1750231059663,mdate = 1753292861331,tcdate = 1737398300520,tmdate = 1753292861331,ddate = None,content = {'title': {'value': 'Continuous Bayesian Model Selection for Multivariate Causal Discovery'}, 'authors': {'value': ['Anish Dhir', 'Ruby Sedgwick', 'Avinash Kori', 'Ben Glocker', 'Mark van der Wilk']}, 'authorids': {'value': ['~Anish_Dhir1', '~Ruby_Sedgwick1', '~Avinash_Kori1', '~Ben_Glocker1', '~Mark_van_der_Wilk1']}, 'TLDR': {'value': 'Bayesian model selection for multivariate causal discovery allows for using more flexible models which leads to better performance.'}, 'abstract': {'value': 'Current causal discovery approaches require restrictive model assumptions in the absence of interventional data to ensure structure identifiability. These assumptions often do not hold in real-world applications leading to a loss of guarantees and poor performance in practice. Recent work has shown that, in the bivariate case, Bayesian model selection can greatly improve performance by exchanging restrictive modelling for more flexible assumptions, at the cost of a small probability of making an error. Our work shows that this approach is useful in the important multivariate case as well. We propose a scalable algorithm leveraging a continuous relaxation of the discrete model selection problem. Specifically, we employ the Causal Gaussian Process Conditional Density Estimator (CGP-CDE) as a Bayesian non-parametric model, using its hyperparameters to construct an adjacency matrix. This matrix is then optimised using the marginal likelihood and an acyclicity regulariser, giving the maximum a posteriori causal graph. We demonstrate the competitiveness of our approach, showing it is advantageous to perform multivariate causal discovery without infeasible assumptions using Bayesian model selection.'}, 'primary_area': {'value': 'general_machine_learning->causality'}, 'keywords': {'value': ['bayesian model selection', 'gaussian process', 'causal discovery']}, 'venue': {'value': 'ICML 2025 poster'}, 'venueid': {'value': 'ICML.cc/2025/Conference'}, 'pdf': {'value': '/pdf/2fac68626ebf03f5b4154d9226166b772b4c4f0b.pdf'}, '_bibtex': {'value': '@inproceedings{\\ndhir2025continuous,\\ntitle={Continuous Bayesian Model Selection for Multivariate Causal Discovery},\\nauthor={Anish Dhir and Ruby Sedgwick and Avinash Kori and Ben Glocker and Mark van der Wilk},\\nbooktitle={Forty-second International Conference on Machine Learning},\\nyear={2025},\\nurl={https://openreview.net/forum?id=zydNWJzoVd}\\n}'}, 'lay_summary': {'value': \"Scientists often want to understand cause-and-effect relationships from data, like determining whether smoking causes cancer or if education leads to higher income. Current methods for discovering these relationships from observational data require very strict assumptions that rarely hold true in real-world situations, leading to unreliable results. We developed a new approach that uses Bayesian statistics to be more flexible about these assumptions while still providing reliable answers. Our method uses advanced machine learning techniques to model the relationships between multiple variables simultaneously, then finds the most likely cause-and-effect structure. \\nOur technique outperforms existing methods where their strict assumptions don't hold. This makes causal discovery more reliable and accessible for scientists studying complex systems with multiple interacting factors, from medical research to economics.\"}, 'link_to_code': {'value': 'https://github.com/Anish144/ContinuousBMSStructureLearning'}, 'paperhash': {'value': 'dhir|continuous_bayesian_model_selection_for_multivariate_causal_discovery'}},forum = 'zydNWJzoVd',replyto = None,readers = ['everyone'],nonreaders = None,signatures = ['ICML.cc/2025/Conference/Submission4001/Authors'],writers = ['ICML.cc/2025/Conference', 'ICML.cc/2025/Conference/Submission4001/Authors'],details = None,invitations = ['ICML.cc/2025/Conference/-/Submission', 'ICML.cc/2025/Conference/-/Post_Submission', 'ICML.cc/2025/Conference/Submission4001/-/Full_Submission', 'ICML.cc/2025/Conference/-/Edit', 'ICML.cc/2025/Conference/Submission4001/-/Camera_Ready_Revision'],parent_invitations = None,domain = 'ICML.cc/2025/Conference',license = 'CC BY 4.0')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# —— 小工具：统一不同格式的取值 ——\n",
        "def val(x):\n",
        "    # content 里既可能是 {\"value\": \"...\"} 也可能直接是字符串/列表\n",
        "    if isinstance(x, dict) and \"value\" in x:\n",
        "        return x.get(\"value\")\n",
        "    return x\n",
        "\n",
        "def to_list(x):\n",
        "    x = val(x)\n",
        "    if x is None:\n",
        "        return []\n",
        "    if isinstance(x, str):\n",
        "        # 关键词可能是逗号/分号分隔的一串\n",
        "        parts = [p.strip() for p in x.replace(\"；\", \";\").replace(\"，\", \",\").split(\",\")]\n",
        "        parts = sum([p.split(\";\") for p in parts], [])\n",
        "        return [p.strip() for p in parts if p.strip()]\n",
        "    if isinstance(x, (list, tuple)):\n",
        "        return [val(i) for i in x]\n",
        "    return [x]\n",
        "\n",
        "def to_str(x):\n",
        "    x = val(x)\n",
        "    if x is None:\n",
        "        return \"\"\n",
        "    if isinstance(x, (list, tuple)):\n",
        "        return \", \".join([str(val(i)) for i in x])\n",
        "    return str(x)\n",
        "\n",
        "# —— 可选：用新接口，避免“iterget_notes 已废弃”的警告 ——\n",
        "# notes = list(client.get_all_notes(invitation=\"ICML.cc/2025/Conference/-/Submission\"))\n",
        "\n",
        "# 你已有的 notes 列表（ICML25_notes）也可以直接用\n",
        "notes = ICML25_notes\n",
        "\n",
        "export = []\n",
        "for n in notes:\n",
        "    c = n.content or {}\n",
        "\n",
        "    item = {\n",
        "        # 基本信息\n",
        "        \"id\": getattr(n, \"id\", None),\n",
        "        \"forum\": getattr(n, \"forum\", None),\n",
        "        \"number\": getattr(n, \"number\", None),\n",
        "        \"created\": getattr(n, \"cdate\", getattr(n, \"created\", None)),\n",
        "        \"created_iso\": datetime.utcfromtimestamp(\n",
        "            int(getattr(n, \"cdate\", getattr(n, \"created\", 0))) / 1000\n",
        "        ).isoformat() + \"Z\" if getattr(n, \"cdate\", getattr(n, \"created\", None)) else None,\n",
        "\n",
        "        # content 常见字段（都做了兼容）\n",
        "        \"title\": to_str(c.get(\"title\")),\n",
        "        \"tldr\": to_str(c.get(\"TLDR\") or c.get(\"tldr\")),\n",
        "        \"abstract\": to_str(c.get(\"abstract\")),\n",
        "        \"lay_summary\": to_str(c.get(\"lay_summary\")),\n",
        "        \"primary_area\": to_str(c.get(\"primary_area\")),\n",
        "        \"venue\": to_str(c.get(\"venue\")),\n",
        "        \"venueid\": to_str(c.get(\"venueid\")),\n",
        "        \"paperhash\": to_str(c.get(\"paperhash\")),\n",
        "        \"_bibtex\": to_str(c.get(\"_bibtex\")),\n",
        "\n",
        "        # 列表类字段\n",
        "        \"authors\": to_list(c.get(\"authors\")),\n",
        "        \"authorids\": to_list(c.get(\"authorids\")),\n",
        "        \"keywords\": to_list(c.get(\"keywords\")),\n",
        "\n",
        "        # 链接类字段\n",
        "        \"pdf\": to_str(c.get(\"pdf\")),\n",
        "        \"link_to_code\": to_str(c.get(\"link_to_code\") or c.get(\"code_of_conduct\") or c.get(\"code_link\")),\n",
        "    }\n",
        "\n",
        "    export.append(item)\n",
        "\n",
        "# —— 保存为 JSON（数组）——\n",
        "with open(\"ICML2025_submissions.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(export, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# —— 也可同时保存 JSONL（每行一条，方便下游处理）——\n",
        "with open(\"ICML2025_submissions.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for row in export:\n",
        "        f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(f\"✅ 导出 {len(export)} 条记录 -> ICML2025_submissions.json / .jsonl\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMK3G5uPURhR",
        "outputId": "eab1bf54-80aa-45b3-883a-a4114bbe22b3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2469241676.py:48: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
            "  \"created_iso\": datetime.utcfromtimestamp(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 导出 3422 条记录 -> ICML2025_submissions.json / .jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openreview import Client\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "client = openreview.api.OpenReviewClient(  # 新版命名空间\n",
        "    baseurl=\"https://api2.openreview.net\",\n",
        "    username=\"yichi.zhang@stonybrook.edu\",\n",
        "    password=\"Zz76146379?\"\n",
        ")\n",
        "\n",
        "INV = \"NeurIPS.cc/2024/Conference/-/Submission\"  # 或类似\n",
        "NIPS24_notes = list(client.get_all_notes(invitation=INV))\n",
        "print(\"抓取条目数：\", len(notes))\n",
        "# 然后筛读权限为 Everyone 的条目，导出 JSON\n",
        "export = []\n",
        "for n in NIPS24_notes:\n",
        "    if \"everyone\" in [r for r in (getattr(n, \"readers\", []) or [])]:\n",
        "        content = n.content or {}\n",
        "        export.append({\n",
        "            \"id\": n.id,\n",
        "            \"title\": content.get(\"title\", {}).get(\"value\", \"\"),\n",
        "            \"abstract\": content.get(\"abstract\", {}).get(\"value\", \"\"),\n",
        "            # … 更多字段\n",
        "        })\n",
        "with open(\"NeurIPS2024_public_submissions.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(export, f, ensure_ascii=False, indent=2)\n",
        "print(\"公开条目数：\", len(export))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rIf3pWyVEEQ",
        "outputId": "e45529b0-3da9-4ca0-e4b9-2c5a64d47021"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "抓取条目数： 3422\n",
            "公开条目数： 4236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# —— 小工具：统一不同格式的取值 ——\n",
        "def val(x):\n",
        "    # content 里既可能是 {\"value\": \"...\"} 也可能直接是字符串/列表\n",
        "    if isinstance(x, dict) and \"value\" in x:\n",
        "        return x.get(\"value\")\n",
        "    return x\n",
        "\n",
        "def to_list(x):\n",
        "    x = val(x)\n",
        "    if x is None:\n",
        "        return []\n",
        "    if isinstance(x, str):\n",
        "        # 关键词可能是逗号/分号分隔的一串\n",
        "        parts = [p.strip() for p in x.replace(\"；\", \";\").replace(\"，\", \",\").split(\",\")]\n",
        "        parts = sum([p.split(\";\") for p in parts], [])\n",
        "        return [p.strip() for p in parts if p.strip()]\n",
        "    if isinstance(x, (list, tuple)):\n",
        "        return [val(i) for i in x]\n",
        "    return [x]\n",
        "\n",
        "def to_str(x):\n",
        "    x = val(x)\n",
        "    if x is None:\n",
        "        return \"\"\n",
        "    if isinstance(x, (list, tuple)):\n",
        "        return \", \".join([str(val(i)) for i in x])\n",
        "    return str(x)\n",
        "\n",
        "# —— 可选：用新接口，避免“iterget_notes 已废弃”的警告 ——\n",
        "# notes = list(client.get_all_notes(invitation=\"ICML.cc/2025/Conference/-/Submission\"))\n",
        "\n",
        "# 你已有的 notes 列表（ICML25_notes）也可以直接用\n",
        "notes = NIPS24_notes\n",
        "\n",
        "export = []\n",
        "for n in notes:\n",
        "    c = n.content or {}\n",
        "\n",
        "    item = {\n",
        "        # 基本信息\n",
        "        \"id\": getattr(n, \"id\", None),\n",
        "        \"forum\": getattr(n, \"forum\", None),\n",
        "        \"number\": getattr(n, \"number\", None),\n",
        "        \"created\": getattr(n, \"cdate\", getattr(n, \"created\", None)),\n",
        "        \"created_iso\": datetime.utcfromtimestamp(\n",
        "            int(getattr(n, \"cdate\", getattr(n, \"created\", 0))) / 1000\n",
        "        ).isoformat() + \"Z\" if getattr(n, \"cdate\", getattr(n, \"created\", None)) else None,\n",
        "\n",
        "        # content 常见字段（都做了兼容）\n",
        "        \"title\": to_str(c.get(\"title\")),\n",
        "        \"tldr\": to_str(c.get(\"TLDR\") or c.get(\"tldr\")),\n",
        "        \"abstract\": to_str(c.get(\"abstract\")),\n",
        "        \"lay_summary\": to_str(c.get(\"lay_summary\")),\n",
        "        \"primary_area\": to_str(c.get(\"primary_area\")),\n",
        "        \"venue\": to_str(c.get(\"venue\")),\n",
        "        \"venueid\": to_str(c.get(\"venueid\")),\n",
        "        \"paperhash\": to_str(c.get(\"paperhash\")),\n",
        "        \"_bibtex\": to_str(c.get(\"_bibtex\")),\n",
        "\n",
        "        # 列表类字段\n",
        "        \"authors\": to_list(c.get(\"authors\")),\n",
        "        \"authorids\": to_list(c.get(\"authorids\")),\n",
        "        \"keywords\": to_list(c.get(\"keywords\")),\n",
        "\n",
        "        # 链接类字段\n",
        "        \"pdf\": to_str(c.get(\"pdf\")),\n",
        "        \"link_to_code\": to_str(c.get(\"link_to_code\") or c.get(\"code_of_conduct\") or c.get(\"code_link\")),\n",
        "    }\n",
        "\n",
        "    export.append(item)\n",
        "\n",
        "# —— 保存为 JSON（数组）——\n",
        "with open(\"NIPS24_submissions.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(export, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# —— 也可同时保存 JSONL（每行一条，方便下游处理）——\n",
        "with open(\"NIPS24_submissions.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for row in export:\n",
        "        f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(f\"✅ 导出 {len(export)} 条记录 -> NIPS24_submissions.json / .jsonl\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "By5dwT3iagmZ",
        "outputId": "18798fe5-8073-4775-9a3b-e4e1dda3f228"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3125982031.py:48: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
            "  \"created_iso\": datetime.utcfromtimestamp(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 导出 4236 条记录 -> NIPS24_submissions.json / .jsonl\n"
          ]
        }
      ]
    }
  ]
}